{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9249187e-9e8d-4efa-a582-0afdf088edea",
   "metadata": {},
   "source": [
    "# Tratamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9ca595e-20c9-4f71-90ae-273e5fc9413f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teste\n",
      "oi\n"
     ]
    }
   ],
   "source": [
    "print('teste')\n",
    "variavel = 'oi'\n",
    "print(variavel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff27d50d-d0e4-415d-8c19-a15ff85ab366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "#ignorando Warning inuteis\n",
    "import warnings \n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7ebc166-97b7-4002-b316-a1f5a86c4e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500        S\n",
       "1         1       1  female  38.0      1      0  71.2833        C\n",
       "2         1       3  female  26.0      0      0   7.9250        S\n",
       "3         1       1  female  35.0      1      0  53.1000        S\n",
       "4         0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar os dados\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Identificar colunas a serem removidas # Remover colunas inÃºteis\n",
    "columns_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "df = df.dropna()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25d815dc-56d2-498a-9003-a6168b75abc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 niveis: Pclass => [3 1 2]\n",
      "2 niveis: Sex => ['male' 'female']\n",
      "3 niveis: Embarked => ['S' 'C' 'Q']\n"
     ]
    }
   ],
   "source": [
    "colunas_cat = ['Pclass','Sex','Embarked']\n",
    "for coluna in colunas_cat:\n",
    "    df[coluna] = df[coluna].astype('O')\n",
    "\n",
    "colunas_binarias = []\n",
    "for coluna in df.columns:\n",
    "    if df[coluna].dtype == 'O':\n",
    "        categorias = df[coluna].unique()\n",
    "        if len(categorias) == 2:\n",
    "            print('2 niveis:', coluna, '=>', categorias)\n",
    "            colunas_binarias.append(coluna)\n",
    "        else:\n",
    "            print('3 niveis:', coluna, '=>', categorias)\n",
    "            colunas_binarias.append(coluna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1d2e7f2-5179-484d-9662-b0197f3fbaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "x_inteiro = x\n",
    "y_inteiro = y\n",
    "\n",
    "#colunas_binarias.remove('Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f7fe409-d4bf-43ed-bdf4-ce3515c7518e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onehotencoder__Pclass_1</th>\n",
       "      <th>onehotencoder__Pclass_2</th>\n",
       "      <th>onehotencoder__Pclass_3</th>\n",
       "      <th>onehotencoder__Sex_male</th>\n",
       "      <th>onehotencoder__Embarked_C</th>\n",
       "      <th>onehotencoder__Embarked_Q</th>\n",
       "      <th>onehotencoder__Embarked_S</th>\n",
       "      <th>remainder__Age</th>\n",
       "      <th>remainder__SibSp</th>\n",
       "      <th>remainder__Parch</th>\n",
       "      <th>remainder__Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   onehotencoder__Pclass_1  onehotencoder__Pclass_2  onehotencoder__Pclass_3  \\\n",
       "0                      0.0                      0.0                      1.0   \n",
       "1                      1.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      1.0   \n",
       "3                      1.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      1.0   \n",
       "\n",
       "   onehotencoder__Sex_male  onehotencoder__Embarked_C  \\\n",
       "0                      1.0                        0.0   \n",
       "1                      0.0                        1.0   \n",
       "2                      0.0                        0.0   \n",
       "3                      0.0                        0.0   \n",
       "4                      1.0                        0.0   \n",
       "\n",
       "   onehotencoder__Embarked_Q  onehotencoder__Embarked_S  remainder__Age  \\\n",
       "0                        0.0                        1.0            22.0   \n",
       "1                        0.0                        0.0            38.0   \n",
       "2                        0.0                        1.0            26.0   \n",
       "3                        0.0                        1.0            35.0   \n",
       "4                        0.0                        1.0            35.0   \n",
       "\n",
       "   remainder__SibSp  remainder__Parch  remainder__Fare  \n",
       "0               1.0               0.0           7.2500  \n",
       "1               1.0               0.0          71.2833  \n",
       "2               0.0               0.0           7.9250  \n",
       "3               1.0               0.0          53.1000  \n",
       "4               0.0               0.0           8.0500  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DUMMYRISAÃÃO\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder #transformando colunas com 2 categorias em 0 e 1\n",
    "\n",
    "coluna = x.columns\n",
    "one_hot = make_column_transformer((\n",
    "    OneHotEncoder(drop='if_binary'), #caso a coluna tenha apenas 2 categorias \n",
    "    colunas_binarias), #passando quais sÃ£o essas colunas\n",
    "    remainder = 'passthrough', sparse_threshold=0) #oque deve ser feito com as outras\n",
    "\n",
    "#Aplicando transformaÃ§Ã£o\n",
    "x = one_hot.fit_transform(x)\n",
    "\n",
    "#Os novos nomes das colunas #'onehotencoder=transformadas; 'remainder'=nÃ£o transformadas\n",
    "novos_nomes_colunas = one_hot.get_feature_names_out(coluna)\n",
    "\n",
    "########################################################################################\n",
    "# PADRONIZAÃÃO DOS DADOS\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "normalizacao = MinMaxScaler()\n",
    "#x = normalizacao.fit_transform(x)\n",
    "\n",
    "x = pd.DataFrame(x, columns = novos_nomes_colunas) #alterando de volta\n",
    "x_columns = x.columns.tolist() \n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1cdc01f-4ed2-46e2-9e27-1dc5cd6dcd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((534, 7), (178, 7), (534,), (178,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SEPARANDO DADOS PARA TREINO E TESTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "x, x_teste, y, y_teste = train_test_split(x_inteiro, y_inteiro, \n",
    "                                          #stratify = y, #para manter a proporÃ§Ã£o da Var Dep nos splits\n",
    "                                          random_state = 5, #raiz da aleatoridade\n",
    "                                          test_size = 0.25) #porcentagem que ira ser separado para testes\n",
    "\n",
    "x.shape, x_teste.shape, y.shape, y_teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f707d0d-2140-4b64-9fe3-d43eb943b20f",
   "metadata": {},
   "source": [
    "# FUNÃÃES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef9a535-b89d-43dd-b8f8-57d47b17fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODIGOS PARA VALIDAÃÃO\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, RocCurveDisplay\n",
    "\n",
    "def avaliar_modelo(y_verdadeiro, y_predito, conjunto_nome):\n",
    "    \"\"\"\n",
    "    FunÃ§Ã£o para avaliar e imprimir o relatÃ³rio de classificaÃ§Ã£o e a matriz de confusÃ£o.\n",
    "    \"\"\"\n",
    "    #if conjunto_nome == \"Treino\":\n",
    "     #   pass\n",
    "    #else:\n",
    "    print('*' * 70)\n",
    "    print(\"RelatÃ³rio de ClassificaÃ§Ã£o para o Conjunto de\", conjunto_nome,\":\\n\")\n",
    "    print(classification_report(y_verdadeiro, y_predito))\n",
    "    \n",
    "    print('*' * 55)\n",
    "    \n",
    "    print(\"Matriz de ConfusÃ£o para o Conjunto de\", conjunto_nome,\":\\n\")\n",
    "    print(confusion_matrix(y_verdadeiro, y_predito))\n",
    "    print('*' * 70)\n",
    "\n",
    "    display(RocCurveDisplay.from_predictions(y_verdadeiro, y_predito, name = conjunto_nome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa421494-d48e-4911-a3db-510951119017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervalo_conf(resultados):\n",
    "    media = resultados.mean()\n",
    "    desvio_padrao = resultados.std()\n",
    "    ic_0 = round(media - 2*desvio_padrao, 2)\n",
    "    ic_1 = round(min(media + 2*desvio_padrao, 1), 2)\n",
    "    ic = '[' + str(ic_0) + ' - ' + str(ic_1) + ']'\n",
    "    return ic\n",
    "\n",
    "def histograma(dados):\n",
    "    dados = dados\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.hist(dados, edgecolor='black', density=True) #bins=q_bins, \n",
    "\n",
    "    plt.title('hist', fontsize=15)\n",
    "    plt.grid(True, color='gray')\n",
    "\n",
    "    # Adicionar linhas verticais para mÃ©dia e mediana\n",
    "    plt.axvline(x = dados.mean(), color='red', linestyle='--', label='MÃ©dia')\n",
    "    plt.axvline(x = dados.median(), color='blue', linestyle='--', label='Mediana')\n",
    "\n",
    "    # Adicionar legenda personalizada\n",
    "    texto_count = 'Count = ' + str(round(len(dados), 0))\n",
    "    texto_media = 'MÃ©dia = '+ str(round(dados.mean(), 2))\n",
    "    texto_dp = 'DP = '+ str(round(dados.std(), 2))\n",
    "    texto_min = 'Min = '+ str(round(dados.min(), 2))\n",
    "    texto_Q1 = 'Q1 = ' + str(round(dados.quantile(0.25), 2))\n",
    "    texto_mediana = 'Q2 = '+ str(round(dados.median(), 2))\n",
    "    texto_Q3 = 'Q3 = ' + str(round(dados.quantile(0.75), 2))\n",
    "    texto_max = 'Max = '+ str(round(dados.max(), 2))\n",
    "    ic = 'IC ' + intervalo_conf(dados)\n",
    "    texto_legenda = '\\n'.join([texto_count, \n",
    "                               texto_min,\n",
    "                               texto_media, texto_dp, \n",
    "                               texto_Q1, texto_mediana, texto_Q3,\n",
    "                               texto_max, \n",
    "                               ic])\n",
    "\n",
    "    plt.text(0.99, 0.96, texto_legenda, ha='right', va='top', transform=plt.gca().transAxes,\n",
    "             bbox=dict(facecolor='black', edgecolor='gray', boxstyle='round'),\n",
    "             fontsize=12)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553c5c73-3c5f-4ec4-903d-840a5275757e",
   "metadata": {},
   "source": [
    "# Modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e92af-57c6-4997-a8b0-bb5f0cbed77c",
   "metadata": {},
   "source": [
    "## LazyClassifier\n",
    "\n",
    "LazyPedict Ã© uma biblioteca que ajuda a semi-automatizar os modelos de Machine Learning.\r\n",
    "\r\n",
    "Essa biblioteca constrÃ³i muitos modelos bÃ¡sicos sem muito cÃ³digo e ajuda a entender quais modelos funcionam melhor sem qualquer ajuste de parÃ¢metro.\r\n",
    "\r\n",
    "ApÃ³s a obtenÃ§Ã£o dos resultados de acurÃ¡cia e avaliaÃ§Ã£o das mÃ©tricas podemos escolher os melhores modelos e aplicar o ajuste de hiperparÃ¢metros a eles.\r\n",
    "\r\n",
    "EntÃ£o, no caso dos dados deste projeto vou usar o LazyClassifier para tentar resolver o problema de classificaÃ§Ã£o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a866c8d3-aef4-4407-90c1-df3564f3f533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 29/29 [00:02<00:00, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 224, number of negative: 310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 184\n",
      "[LightGBM] [Info] Number of data points in the train set: 534, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.419476 -> initscore=-0.324926\n",
      "[LightGBM] [Info] Start training from score -0.324926\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "LGBMClassifier                     0.83               0.83     0.83      0.83   \n",
       "XGBClassifier                      0.82               0.82     0.82      0.82   \n",
       "SVC                                0.84               0.82     0.82      0.84   \n",
       "NuSVC                              0.84               0.82     0.82      0.84   \n",
       "LabelPropagation                   0.82               0.80     0.80      0.82   \n",
       "LabelSpreading                     0.82               0.80     0.80      0.82   \n",
       "KNeighborsClassifier               0.83               0.80     0.80      0.83   \n",
       "LogisticRegression                 0.82               0.80     0.80      0.82   \n",
       "RandomForestClassifier             0.81               0.80     0.80      0.81   \n",
       "ExtraTreesClassifier               0.81               0.80     0.80      0.81   \n",
       "ExtraTreeClassifier                0.80               0.79     0.79      0.80   \n",
       "RidgeClassifierCV                  0.81               0.79     0.79      0.81   \n",
       "RidgeClassifier                    0.81               0.79     0.79      0.81   \n",
       "LinearSVC                          0.81               0.79     0.79      0.81   \n",
       "LinearDiscriminantAnalysis         0.81               0.79     0.79      0.81   \n",
       "CalibratedClassifierCV             0.81               0.79     0.79      0.81   \n",
       "NearestCentroid                    0.80               0.78     0.78      0.80   \n",
       "AdaBoostClassifier                 0.80               0.78     0.78      0.80   \n",
       "DecisionTreeClassifier             0.79               0.78     0.78      0.79   \n",
       "BernoulliNB                        0.78               0.77     0.77      0.78   \n",
       "GaussianNB                         0.79               0.77     0.77      0.79   \n",
       "BaggingClassifier                  0.79               0.76     0.76      0.79   \n",
       "Perceptron                         0.82               0.76     0.76      0.81   \n",
       "QuadraticDiscriminantAnalysis      0.73               0.74     0.74      0.74   \n",
       "SGDClassifier                      0.76               0.74     0.74      0.76   \n",
       "PassiveAggressiveClassifier        0.79               0.74     0.74      0.78   \n",
       "DummyClassifier                    0.64               0.50     0.50      0.50   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "LGBMClassifier                       0.27  \n",
       "XGBClassifier                        0.14  \n",
       "SVC                                  0.04  \n",
       "NuSVC                                0.04  \n",
       "LabelPropagation                     0.05  \n",
       "LabelSpreading                       0.03  \n",
       "KNeighborsClassifier                 0.04  \n",
       "LogisticRegression                   0.03  \n",
       "RandomForestClassifier               0.24  \n",
       "ExtraTreesClassifier                 0.36  \n",
       "ExtraTreeClassifier                  0.02  \n",
       "RidgeClassifierCV                    0.03  \n",
       "RidgeClassifier                      0.07  \n",
       "LinearSVC                            0.04  \n",
       "LinearDiscriminantAnalysis           0.05  \n",
       "CalibratedClassifierCV               0.18  \n",
       "NearestCentroid                      0.06  \n",
       "AdaBoostClassifier                   0.11  \n",
       "DecisionTreeClassifier               0.03  \n",
       "BernoulliNB                          0.04  \n",
       "GaussianNB                           0.06  \n",
       "BaggingClassifier                    0.05  \n",
       "Perceptron                           0.02  \n",
       "QuadraticDiscriminantAnalysis        0.01  \n",
       "SGDClassifier                        0.04  \n",
       "PassiveAggressiveClassifier          0.02  \n",
       "DummyClassifier                      0.04  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier, LazyRegressor\n",
    "\n",
    "np.random.seed(73246) #para garantir a reprodutibilidade\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.2, random_state=0)\n",
    "\n",
    "# fit all models\n",
    "clf = LazyClassifier(predictions=True)\n",
    "models, predictions = clf.fit(x, x_teste, y, y_teste) \n",
    "'''\"clf\" estÃ¡ retornando dois valores, Modelo e PrevisÃ£o, enquanto modelo significa \n",
    "todos os modelos e com algumas mÃ©tricas e previsÃ£o significa todo o valor previsto que Ã© Å·'''\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc891a-5f3e-4a70-9cd9-1e9780d68cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f033c824-4d36-4f26-bfaf-73f9d797544c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd7aa0d-8add-47c0-98a7-5fd2c15b2585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f13c8e-8951-490f-9ed4-f687af2b359b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387eb77f-6054-4667-866a-fe2080bfb2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
