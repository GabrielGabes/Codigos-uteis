{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9249187e-9e8d-4efa-a582-0afdf088edea",
   "metadata": {},
   "source": [
    "# Tratamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9ca595e-20c9-4f71-90ae-273e5fc9413f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teste\n",
      "oi\n"
     ]
    }
   ],
   "source": [
    "print('teste')\n",
    "variavel = 'oi'\n",
    "print(variavel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff27d50d-d0e4-415d-8c19-a15ff85ab366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "#ignorando Warning inuteis\n",
    "import warnings \n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7ebc166-97b7-4002-b316-a1f5a86c4e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500        S\n",
       "1         1       1  female  38.0      1      0  71.2833        C\n",
       "2         1       3  female  26.0      0      0   7.9250        S\n",
       "3         1       1  female  35.0      1      0  53.1000        S\n",
       "4         0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar os dados\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Identificar colunas a serem removidas # Remover colunas inúteis\n",
    "columns_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "df = df.dropna()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25d815dc-56d2-498a-9003-a6168b75abc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 niveis: Pclass => [3 1 2]\n",
      "2 niveis: Sex => ['male' 'female']\n",
      "3 niveis: Embarked => ['S' 'C' 'Q']\n"
     ]
    }
   ],
   "source": [
    "colunas_cat = ['Pclass','Sex','Embarked']\n",
    "for coluna in colunas_cat:\n",
    "    df[coluna] = df[coluna].astype('O')\n",
    "\n",
    "colunas_binarias = []\n",
    "for coluna in df.columns:\n",
    "    if df[coluna].dtype == 'O':\n",
    "        categorias = df[coluna].unique()\n",
    "        if len(categorias) == 2:\n",
    "            print('2 niveis:', coluna, '=>', categorias)\n",
    "            colunas_binarias.append(coluna)\n",
    "        else:\n",
    "            print('3 niveis:', coluna, '=>', categorias)\n",
    "            colunas_binarias.append(coluna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1d2e7f2-5179-484d-9662-b0197f3fbaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "x_inteiro = x\n",
    "y_inteiro = y\n",
    "\n",
    "#colunas_binarias.remove('Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f7fe409-d4bf-43ed-bdf4-ce3515c7518e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onehotencoder__Pclass_1</th>\n",
       "      <th>onehotencoder__Pclass_2</th>\n",
       "      <th>onehotencoder__Pclass_3</th>\n",
       "      <th>onehotencoder__Sex_male</th>\n",
       "      <th>onehotencoder__Embarked_C</th>\n",
       "      <th>onehotencoder__Embarked_Q</th>\n",
       "      <th>onehotencoder__Embarked_S</th>\n",
       "      <th>remainder__Age</th>\n",
       "      <th>remainder__SibSp</th>\n",
       "      <th>remainder__Parch</th>\n",
       "      <th>remainder__Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   onehotencoder__Pclass_1  onehotencoder__Pclass_2  onehotencoder__Pclass_3  \\\n",
       "0                      0.0                      0.0                      1.0   \n",
       "1                      1.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      1.0   \n",
       "3                      1.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      1.0   \n",
       "\n",
       "   onehotencoder__Sex_male  onehotencoder__Embarked_C  \\\n",
       "0                      1.0                        0.0   \n",
       "1                      0.0                        1.0   \n",
       "2                      0.0                        0.0   \n",
       "3                      0.0                        0.0   \n",
       "4                      1.0                        0.0   \n",
       "\n",
       "   onehotencoder__Embarked_Q  onehotencoder__Embarked_S  remainder__Age  \\\n",
       "0                        0.0                        1.0            22.0   \n",
       "1                        0.0                        0.0            38.0   \n",
       "2                        0.0                        1.0            26.0   \n",
       "3                        0.0                        1.0            35.0   \n",
       "4                        0.0                        1.0            35.0   \n",
       "\n",
       "   remainder__SibSp  remainder__Parch  remainder__Fare  \n",
       "0               1.0               0.0           7.2500  \n",
       "1               1.0               0.0          71.2833  \n",
       "2               0.0               0.0           7.9250  \n",
       "3               1.0               0.0          53.1000  \n",
       "4               0.0               0.0           8.0500  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DUMMYRISAÇÃO\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder #transformando colunas com 2 categorias em 0 e 1\n",
    "\n",
    "coluna = x.columns\n",
    "one_hot = make_column_transformer((\n",
    "    OneHotEncoder(drop='if_binary'), #caso a coluna tenha apenas 2 categorias \n",
    "    colunas_binarias), #passando quais são essas colunas\n",
    "    remainder = 'passthrough', sparse_threshold=0) #oque deve ser feito com as outras\n",
    "\n",
    "#Aplicando transformação\n",
    "x = one_hot.fit_transform(x)\n",
    "\n",
    "#Os novos nomes das colunas #'onehotencoder=transformadas; 'remainder'=não transformadas\n",
    "novos_nomes_colunas = one_hot.get_feature_names_out(coluna)\n",
    "\n",
    "########################################################################################\n",
    "# PADRONIZAÇÃO DOS DADOS\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "normalizacao = MinMaxScaler()\n",
    "#x = normalizacao.fit_transform(x)\n",
    "\n",
    "x = pd.DataFrame(x, columns = novos_nomes_colunas) #alterando de volta\n",
    "x_columns = x.columns.tolist() \n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1cdc01f-4ed2-46e2-9e27-1dc5cd6dcd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((534, 7), (178, 7), (534,), (178,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SEPARANDO DADOS PARA TREINO E TESTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "x, x_teste, y, y_teste = train_test_split(x_inteiro, y_inteiro, \n",
    "                                          #stratify = y, #para manter a proporção da Var Dep nos splits\n",
    "                                          random_state = 5, #raiz da aleatoridade\n",
    "                                          test_size = 0.25) #porcentagem que ira ser separado para testes\n",
    "\n",
    "x.shape, x_teste.shape, y.shape, y_teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f707d0d-2140-4b64-9fe3-d43eb943b20f",
   "metadata": {},
   "source": [
    "# FUNÇÕES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef9a535-b89d-43dd-b8f8-57d47b17fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODIGOS PARA VALIDAÇÃO\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, RocCurveDisplay\n",
    "\n",
    "def avaliar_modelo(y_verdadeiro, y_predito, conjunto_nome):\n",
    "    \"\"\"\n",
    "    Função para avaliar e imprimir o relatório de classificação e a matriz de confusão.\n",
    "    \"\"\"\n",
    "    #if conjunto_nome == \"Treino\":\n",
    "     #   pass\n",
    "    #else:\n",
    "    print('*' * 70)\n",
    "    print(\"Relatório de Classificação para o Conjunto de\", conjunto_nome,\":\\n\")\n",
    "    print(classification_report(y_verdadeiro, y_predito))\n",
    "    \n",
    "    print('*' * 55)\n",
    "    \n",
    "    print(\"Matriz de Confusão para o Conjunto de\", conjunto_nome,\":\\n\")\n",
    "    print(confusion_matrix(y_verdadeiro, y_predito))\n",
    "    print('*' * 70)\n",
    "\n",
    "    display(RocCurveDisplay.from_predictions(y_verdadeiro, y_predito, name = conjunto_nome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa421494-d48e-4911-a3db-510951119017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervalo_conf(resultados):\n",
    "    media = resultados.mean()\n",
    "    desvio_padrao = resultados.std()\n",
    "    ic_0 = round(media - 2*desvio_padrao, 2)\n",
    "    ic_1 = round(min(media + 2*desvio_padrao, 1), 2)\n",
    "    ic = '[' + str(ic_0) + ' - ' + str(ic_1) + ']'\n",
    "    return ic\n",
    "\n",
    "def histograma(dados):\n",
    "    dados = dados\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.hist(dados, edgecolor='black', density=True) #bins=q_bins, \n",
    "\n",
    "    plt.title('hist', fontsize=15)\n",
    "    plt.grid(True, color='gray')\n",
    "\n",
    "    # Adicionar linhas verticais para média e mediana\n",
    "    plt.axvline(x = dados.mean(), color='red', linestyle='--', label='Média')\n",
    "    plt.axvline(x = dados.median(), color='blue', linestyle='--', label='Mediana')\n",
    "\n",
    "    # Adicionar legenda personalizada\n",
    "    texto_count = 'Count = ' + str(round(len(dados), 0))\n",
    "    texto_media = 'Média = '+ str(round(dados.mean(), 2))\n",
    "    texto_dp = 'DP = '+ str(round(dados.std(), 2))\n",
    "    texto_min = 'Min = '+ str(round(dados.min(), 2))\n",
    "    texto_Q1 = 'Q1 = ' + str(round(dados.quantile(0.25), 2))\n",
    "    texto_mediana = 'Q2 = '+ str(round(dados.median(), 2))\n",
    "    texto_Q3 = 'Q3 = ' + str(round(dados.quantile(0.75), 2))\n",
    "    texto_max = 'Max = '+ str(round(dados.max(), 2))\n",
    "    ic = 'IC ' + intervalo_conf(dados)\n",
    "    texto_legenda = '\\n'.join([texto_count, \n",
    "                               texto_min,\n",
    "                               texto_media, texto_dp, \n",
    "                               texto_Q1, texto_mediana, texto_Q3,\n",
    "                               texto_max, \n",
    "                               ic])\n",
    "\n",
    "    plt.text(0.99, 0.96, texto_legenda, ha='right', va='top', transform=plt.gca().transAxes,\n",
    "             bbox=dict(facecolor='black', edgecolor='gray', boxstyle='round'),\n",
    "             fontsize=12)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553c5c73-3c5f-4ec4-903d-840a5275757e",
   "metadata": {},
   "source": [
    "# Modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e92af-57c6-4997-a8b0-bb5f0cbed77c",
   "metadata": {},
   "source": [
    "## LazyClassifier\n",
    "\n",
    "LazyPedict é uma biblioteca que ajuda a semi-automatizar os modelos de Machine Learning.\r\n",
    "\r\n",
    "Essa biblioteca constrói muitos modelos básicos sem muito código e ajuda a entender quais modelos funcionam melhor sem qualquer ajuste de parâmetro.\r\n",
    "\r\n",
    "Após a obtenção dos resultados de acurácia e avaliação das métricas podemos escolher os melhores modelos e aplicar o ajuste de hiperparâmetros a eles.\r\n",
    "\r\n",
    "Então, no caso dos dados deste projeto vou usar o LazyClassifier para tentar resolver o problema de classificação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a866c8d3-aef4-4407-90c1-df3564f3f533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 224, number of negative: 310\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 184\n",
      "[LightGBM] [Info] Number of data points in the train set: 534, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.419476 -> initscore=-0.324926\n",
      "[LightGBM] [Info] Start training from score -0.324926\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "LGBMClassifier                     0.83               0.83     0.83      0.83   \n",
       "XGBClassifier                      0.82               0.82     0.82      0.82   \n",
       "SVC                                0.84               0.82     0.82      0.84   \n",
       "NuSVC                              0.84               0.82     0.82      0.84   \n",
       "LabelPropagation                   0.82               0.80     0.80      0.82   \n",
       "LabelSpreading                     0.82               0.80     0.80      0.82   \n",
       "KNeighborsClassifier               0.83               0.80     0.80      0.83   \n",
       "LogisticRegression                 0.82               0.80     0.80      0.82   \n",
       "RandomForestClassifier             0.81               0.80     0.80      0.81   \n",
       "ExtraTreesClassifier               0.81               0.80     0.80      0.81   \n",
       "ExtraTreeClassifier                0.80               0.79     0.79      0.80   \n",
       "RidgeClassifierCV                  0.81               0.79     0.79      0.81   \n",
       "RidgeClassifier                    0.81               0.79     0.79      0.81   \n",
       "LinearSVC                          0.81               0.79     0.79      0.81   \n",
       "LinearDiscriminantAnalysis         0.81               0.79     0.79      0.81   \n",
       "CalibratedClassifierCV             0.81               0.79     0.79      0.81   \n",
       "NearestCentroid                    0.80               0.78     0.78      0.80   \n",
       "AdaBoostClassifier                 0.80               0.78     0.78      0.80   \n",
       "DecisionTreeClassifier             0.79               0.78     0.78      0.79   \n",
       "BernoulliNB                        0.78               0.77     0.77      0.78   \n",
       "GaussianNB                         0.79               0.77     0.77      0.79   \n",
       "BaggingClassifier                  0.79               0.76     0.76      0.79   \n",
       "Perceptron                         0.82               0.76     0.76      0.81   \n",
       "QuadraticDiscriminantAnalysis      0.73               0.74     0.74      0.74   \n",
       "SGDClassifier                      0.76               0.74     0.74      0.76   \n",
       "PassiveAggressiveClassifier        0.79               0.74     0.74      0.78   \n",
       "DummyClassifier                    0.64               0.50     0.50      0.50   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "LGBMClassifier                       0.27  \n",
       "XGBClassifier                        0.14  \n",
       "SVC                                  0.04  \n",
       "NuSVC                                0.04  \n",
       "LabelPropagation                     0.05  \n",
       "LabelSpreading                       0.03  \n",
       "KNeighborsClassifier                 0.04  \n",
       "LogisticRegression                   0.03  \n",
       "RandomForestClassifier               0.24  \n",
       "ExtraTreesClassifier                 0.36  \n",
       "ExtraTreeClassifier                  0.02  \n",
       "RidgeClassifierCV                    0.03  \n",
       "RidgeClassifier                      0.07  \n",
       "LinearSVC                            0.04  \n",
       "LinearDiscriminantAnalysis           0.05  \n",
       "CalibratedClassifierCV               0.18  \n",
       "NearestCentroid                      0.06  \n",
       "AdaBoostClassifier                   0.11  \n",
       "DecisionTreeClassifier               0.03  \n",
       "BernoulliNB                          0.04  \n",
       "GaussianNB                           0.06  \n",
       "BaggingClassifier                    0.05  \n",
       "Perceptron                           0.02  \n",
       "QuadraticDiscriminantAnalysis        0.01  \n",
       "SGDClassifier                        0.04  \n",
       "PassiveAggressiveClassifier          0.02  \n",
       "DummyClassifier                      0.04  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier, LazyRegressor\n",
    "\n",
    "np.random.seed(73246) #para garantir a reprodutibilidade\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.2, random_state=0)\n",
    "\n",
    "# fit all models\n",
    "clf = LazyClassifier(predictions=True)\n",
    "models, predictions = clf.fit(x, x_teste, y, y_teste) \n",
    "'''\"clf\" está retornando dois valores, Modelo e Previsão, enquanto modelo significa \n",
    "todos os modelos e com algumas métricas e previsão significa todo o valor previsto que é ŷ'''\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc891a-5f3e-4a70-9cd9-1e9780d68cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f033c824-4d36-4f26-bfaf-73f9d797544c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd7aa0d-8add-47c0-98a7-5fd2c15b2585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f13c8e-8951-490f-9ed4-f687af2b359b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387eb77f-6054-4667-866a-fe2080bfb2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
