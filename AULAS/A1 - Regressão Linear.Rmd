# Análise de Regressão Linear

Este notebook apresenta uma análise de regressão linear, explorando diferentes modelos para entender como as variáveis independentes influenciam uma variável dependente. A regressão linear é uma abordagem estatística que modela a relação entre uma variável dependente e uma ou mais variáveis independentes.

## Suposições dos Modelos Lineares

Modelos lineares fazem suposições específicas sobre os dados:

- **Linearidade**: A relação entre variáveis independentes e a variável dependente deve ser linear.
- **Normalidade dos Resíduos**: Os resíduos do modelo devem seguir uma distribuição normal.
- **Homoscedasticidade**: Variância constante dos resíduos em relação aos valores ajustados.
- **Independência dos Resíduos**: Não deve haver autocorrelação entre os resíduos.

Violando essas suposições, os resultados podem ser enganosos e a eficácia do modelo reduzida.

```{r (Só cabe a regressão linear simples) Relação linear entre as variaveis}

plot(df$idade, df$altura)

ggplot(df, aes(x=idade, y=altura)) + theme_bw() +
  geom_point() + geom_smooth(method = 'lm') +
  #stat_regline_equation() 
  stat_cor()

```


```{r Contruindo modelo}
# modelo nulo
modelo_nulo = lm(altura ~ 1, data=df)

# modelo simples
modelo0 = lm(altura ~ idade, data=df)
#modelo0 %>% summary()

#### modelos multipla ####
modelo = lm(altura ~ idade + peso, data=df)
modelo %>% summary()

# modelo com interação
modelo1 = lm(altura ~ idade * peso, data=df)
#modelo1 %>% summary()

# modelo com transformações
modelo2 = lm(log(altura) ~ sqrt(idade) + peso^2, data=df)
#modelo2 %>% summary()

```

Interpratação dos Resultados

> Estimate: Reflete o impacto estimado da variável independente na variável dependente; Magnitude do impacto da variavel independente sobre a dependente; o quanto a variavel dependente aumenta(ou diminui) a cada acrescimo de unidade medida da variavel independente analisada.

> Pr(>|t|): P-valor testando a hipótese nula de que o coeficiente é zero, significando que a variavel independente não tem impacto para predição da variavel dependente.

> Multiple R-square: pode ser interpretado como uma porcentagem, o quanto a variavel independente esta explicando a dependente/modelo; A proporção da variância na variável dependente que é previsível a partir das variáveis independentes.

> Adjusted R-squared: mais importante em regressão multipla, pq ele corrigi para quantidade de variaveis, pois dai conseguir comparar modelos com quantidade de variaveis diferentes; útil para comparação entre modelos.

> F-statistic: é usada para testar se há evidência de que qualquer uma das variáveis explicativas no modelo tem um efeito significativo. Esta é uma visão de alto nível do modelo.

Comparando a influencia das variaveis dependentes pelo coeficiente padronizado
```{r coeficiente padronizado}
library(QuantPsyc)
lm.beta(modelo)
```


```{r Intervalo de confiança para os coeficientes}
confint(modelo)
```

# Analise de Residuos
```{r Gerando a analise geral}

plot(modelo1)

# par(mfrow=c(2, 2))
# plot(modelo1)
# par(mfrow=c(1, 1))  # Resetando layout

```
> fonte/interpretação: https://data.library.virginia.edu/diagnostic-plots/


## Normalidade dos Residuos:
Se os resíduos seguem uma distribuição normal, então os testes baseados na distribuição t de Student para os coeficientes são válidos.
```{r Normalidade dos Residuos}

df$residuos <- resid(modelo)

#### Teste de hipotese de normalidade ####
shapiro.test(df$residuos)

#### QQplot ####
qqnorm(residuos)
qqline(residuos, col = "red")

#### Histograma ####

hist(residuos, main = "Histograma dos Resíduos", xlab = "Resíduos", breaks = 10)

# Minha função
teste_normalidade(df, 'residuos')

```

Homoscedasticidade: Os resíduos devem ter variância constante em relação aos valores preditos. Se a variância dos resíduos aumenta ou diminui com os valores preditos, isso sugere heteroscedasticidade.
```{r Homoscedasticidade}

# Gráfico de Resíduos vs Valores Ajustados
plot(predict(modelo), residuos, xlab = "Valores Ajustados", ylab = "Resíduos",
     main = "Resíduos vs Valores Ajustados")
abline(h = 0, col = "red")

# Teste de hipotese de Breusch-Pagan
library(lmtest)
bptest(modelo1)

```
>fonte: 
  https://www.statology.org/breusch-pagan-test/
  https://medium.com/@lauradamaceno/entendendo-regress%C3%A3o-linear-as-suposi%C3%A7%C3%B5es-por-tr%C3%A1s-de-tudo-d0e29004c7f8


Ausência de outliers: Outliers podem ter um impacto desproporcional sobre o modelo de regressão linear, e é crucial identificá-los e entender seu impacto.
 
```{r Outliers nos residuos}
summary(rstandard(modelo1))

# Gráfico de Cook's Distance
cooks_dist <- cooks.distance(modelo1)
plot(cooks_dist, type = "h", main = "Cook's Distance", ylab = "Cook's Distance")
abline(h = 4/(nrow(df)-length(coef(modelo1))), col = "red", lty = 2)

# influences texto para pontos influentes
influential <- which(cooks_dist > 4/(nrow(df)-length(coef(modelo1))))
text(influential, cooks_dist[influential], labels = influential, pos = 4)
```


Independência: Os resíduos devem ser independentes entre si, o que é essencial para a validade das estimativas de variância e intervalos de confiança. A dependência pode ser detectada verificando-se padrões nos resíduos ao longo do tempo (em séries temporais, por exemplo **só serve para medidas longitudinais**).

o teste de Durbin-Watson, que é comumente usado para detectar a presença de autocorrelação em resíduos de regressões lineares. Valores próximos de 2 sugerem que não há autocorrelação significativa, enquanto valores significativamente menores ou maiores que 2 indicam autocorrelação positiva ou negativa, respectivamente.

```{r Independência dos residuos}
# Teste de hipotese de Durbin-Watson para autocorrelação
library(lmtest)
dwtest(modelo)

durbinWatsonTest(modelo)
```

```{r Outros}
# Resíduos padronizados
std_resid <- rstandard(modelo1)
plot(std_resid, type = "p", main = "Resíduos Padronizados", ylab = "Resíduos Padronizados")

# Escala-Localização (Spread-Location Plot)
sqrt_abs_std_resid <- sqrt(abs(std_resid))
plot(predict(modelo1), sqrt_abs_std_resid, xlab = "Valores Ajustados", ylab = "Raiz Quadrada dos Resíduos Padronizados",
     main = "Gráfico de Escala-Localização")
abline(h = 0, col = "red", lty = 2)

```

Multicolinearidade:

Não deve haver correlação entre as variáveis independentes, pois atrapalha na estimação dos coeficientes
Valores altos de VIF (tipicamente valores maiores que 10) indicam multicolinearidade problemática.

oque fazer quando haver multicoliearidade:
- Remover uma ou mais das variáveis correlacionadas.

- Combinar variáveis correlacionadas em uma única variável através de técnicas como análise de componentes principais (PCA).

- Usar regularização (como Ridge ou Lasso) que pode ajudar a reduzir o impacto da multicolinearidade ao penalizar coeficientes grandes no modelo.

```{r correlação entre as variáveis independentes}

cor(df[c('altura','idade','peso')])

# inflação da variância (VIF)
library(car)
vif(modelo1)

```
# Metricas de avaliação final

```{r Medidas de avaliação da regressão linear}
metrics_aval = function(modelo, var_y){
  # Previsões do modelo
  predictions = predict(modelo)
  
  # MAE - Mean Absolute Error
  MAE = mean(abs(df[[var_y]] - predictions)) %>% round(2)
  
  # MSE - Mean Squared Error
  MSE = mean((df[[var_y]] - predictions)^2) %>% round(2)
  
  # RMSE - Root Mean Squared Error
  RMSE = sqrt(MSE) %>% round(2)
  
  # MAPE - Mean Absolute Percentage Error
  MAPE = mean(abs((df[[var_y]] - predictions) / df[[var_y]])) * 100
  MAPE = MAPE %>% round(2)
  
  # Teste F para avaliar a significância global do modelo
  # %>% summary()
  AIC = AIC(modelo) %>% round(2) # AIC
  BIC = BIC(modelo) %>% round(2) # BIC
  
  # Significancia Global do Modelo
  Anova = anova(modelo)
  
  # Retorna os resultados concatenados em uma string
  texto_return = paste("MAE:",MAE, "; MSE:",MSE, "; RMSE:",RMSE, "; MAPE:",MAPE, '; AIC|BIC:',AIC,'|',BIC)
  return(texto_return)
}

metrics_aval(modelo0, 'altura')
metrics_aval(modelo1, 'altura')
metrics_aval(modelo2, 'altura')
```

# Comparando modelos aninhados - hierarquico
modelos que são aninhados uns dentro dos outros (ou seja, modelos que diferem por um ou mais termos). Cada linha no resultado da ANOVA representa um modelo, e o teste F é usado para comparar cada modelo com os modelos mais simples anteriores.
testando se a adição de uma outra variável produz uma melhoria significativa no ajuste.

```{r}
#### comparação de modelos 
anova(modelo0, modelo)

```

```{r Métodos de seleção de modelos}

stepAIC(modelo)

```
Este notebook explorou diferentes aspectos e diagnósticos dos modelos de regressão linear. Os modelos foram avaliados e comparados com base em várias métricas e diagnósticos para entender sua eficácia e precisão na previsão da variável dependente.

Referências adicionais e leitura adicional podem ser encontradas nas fontes listadas abaixo.

Fontes:

Regressão linear simples no R: https://youtu.be/E2bYIb81q4A?si=IzRzcd-Rw0LpS3zJ
Regressão linear múltipla no R: https://youtu.be/4YLOwyx_hxo?si=EIZj9hVNzwT_qXtW

https://ibape-nacional.com.br/biblioteca/wp-content/uploads/2021/11/17-An%C3%A1lise-dos-Res%C3%ADduos-na-Regress%C3%A3o-Linear-M%C3%BAltipla-pelo-M%C3%A9todo-dos-M%C3%ADnimos-Quadrados-Ordin%C3%A1rios.pdf

https://medium.com/@lauradamaceno/regress%C3%A3o-linear-6a7f247c3e29

http://professor.ufop.br/sites/default/files/ericarodrigues/files/regressaolinearsimples_parte4.pdf