```{r}
source('https://raw.githubusercontent.com/GabrielGabes/Codigos-uteis/main/R%20program/executar_sempre.R')
df = df_ficticio(6000)
```

```{r}
library(GGally)
library(PerformanceAnalytics)

# Exemplo de matriz de correlação adaptativa com PerformanceAnalytics
chart.Correlation(dff[sapply(dff, is.numeric)], histogram=TRUE, pch=19)
```


```{r}
cor.test(dff$idade, dff$peso, use = "complete.obs") #%>% tidy() %>% .$p.value %>% pval_string()
```

```{r}
cor.hip = function(x, y, rho_null = 0.5, use = 'everything', method = 'pearson'){
  cor_obs = cor(x, y, use = use, method = method)
  
  # rho_null # Definindo o valor da correlação nula (0.5)
  
  # Transformação de Fisher
  z_obs <- atanh(cor_obs)
  z_null <- atanh(rho_null)
  
  # Calculando o valor de t
  n <- sum(complete.cases(x, y))  # Número de observações válidas
  t_value <- (z_obs - z_null) / sqrt(1 / (n - 3))
  
  # Calculando o p-value para a hipótese alternativa que cor > 0.5
  p_value <- pt(t_value, df = n - 1, lower.tail = FALSE)
  
  # Resultado
  list(
    cor = cor_obs,
    t_value = t_value,
    p.value = p_value,
    alternative_hypothesis = paste("correlation >", rho_null)
  )
}

cor.hip(dff$idade, dff$peso)
```


```{r}
teste_num_cat = function(df, col_num, col_cat){
  
  qtd_levels = length(levels(as.factor(df[[col_cat]])))
  
  if (qtd_levels <= 2) {
    # A lógica existente para 2 categorias permanece a mesma
    if (group_normality_test(df, col_num, col_cat, 1)){
      formula = formula(paste0(col_num, '~', col_cat))
      
      # Teste de homogeneidade para 2 grupos
      teste_homogeneidade = bartlett.test(formula, df)
      
      if (teste_homogeneidade$p.value > 0.05){
        teste_usado = "Student's t-test"
        pvalor = t.test(df[[col_num]] ~ df[[col_cat]], var.equal = TRUE)$p.value
      } else {
        teste_usado = "Welch's t-test"
        pvalor = t.test(df[[col_num]] ~ df[[col_cat]], var.equal = FALSE)$p.value
      }
    } else {
      pvalor = wilcox.test(df[[col_num]] ~ df[[col_cat]])$p.value
      teste_usado = "Mann-Whitney"
    }
  } else {
    # Quando houver mais de 2 categorias
    formula = formula(paste0(col_num, '~', col_cat))
    
    if (group_normality_test(df, col_num, col_cat, 1)){
      # Verificando homogeneidade para mais de 2 grupos
      teste_homogeneidade = bartlett.test(formula, df)
      
      if (teste_homogeneidade$p.value > 0.05){
        # Variâncias homogêneas -> ANOVA
        pvalor = summary(aov(df[[col_num]] ~ df[[col_cat]]))[[1]][["Pr(>F)"]][1]
        teste_usado = "One-way ANOVA"
      } else {
        # Variâncias heterogêneas -> Welch ANOVA (Omnibus)
        pvalor = oneway.test(df[[col_num]] ~ df[[col_cat]], var.equal = FALSE)$p.value
        teste_usado = "Welch's ANOVA"
      }
    } else {
      # Se a normalidade não for atendida -> Kruskal-Wallis
      pvalor = kruskal.test(df[[col_num]] ~ df[[col_cat]])$p.value
      teste_usado = "Kruskal-Wallis"
    }
  }
  
  list(p.value = pvalor, 
       test = teste_usado)
}


teste_num_cat(dff, 'desfecho_num', 'asa')

n = 100
cat3 = c(rep("A", n), rep("B", n), rep('C', n))
filtro_A = cat3 == "A"
filtro_B = cat3 == "B"
filtro_C = cat3 == "C"
df = data.frame(cat3 = cat3)
df$numerica = NA
df$numerica[filtro_A] = rnorm(n, mean = 10, sd = 20)
df$numerica[filtro_B] = rnorm(n, mean = 30, sd = 40)
#df$numerica[filtro_C] = rpois(n, 40)
df$numerica[filtro_C] = runif(n)
teste_num_cat(df, 'numerica', 'cat3')
```

# funções reais

```{r}
group_normality_test <- function(df, col_num, col_cat, type_response = 0) {

  # Realizar o teste de normalidade (Shapiro ou KS) para cada grupo
  resultados <- by(df[[col_num]], df[[col_cat]], function(subset) {
    if (length(subset) > 5000) {
      # Aplicar o teste de Kolmogorov-Smirnov se o tamanho do subset for maior que 5000
      test_result <- ks.test(subset, "pnorm", mean(subset, na.rm = TRUE), sd(subset, na.rm = TRUE))
      list(test = test_result, test_type = "ks", n = length(subset))  # Armazenar resultado e tipo de teste
    } else {
      # Aplicar o teste de Shapiro-Wilk se o tamanho do subset for menor ou igual a 5000
      test_result <- shapiro.test(subset)
      list(test = test_result, test_type = "shapiro", n = length(subset))  # Armazenar resultado e tipo de teste
    }
  })

  # Extrair p-valores, tipo de teste e contagem de observações
  p_values <- sapply(resultados, function(result) result$test$p.value)
  test_types <- sapply(resultados, function(result) result$test_type)
  counts <- sapply(resultados, function(result) result$n)

  # Verificar se algum p-valor indica não normalidade
  verificacao <- any(p_values < 0.05)

  # Criar a tabela com grupo, p-valor, tipo de teste e contagem de observações
  tabela <- data.frame(
    group = names(p_values),
    p_value = p_values,
    test_used = test_types,
    n_observations = counts
  )
  
  rownames(tabela) <- NULL  # Remover os nomes das linhas

  # Retornar os resultados com base no parâmetro type_response
  if (type_response == 0) {
    return(tabela)  # Retorna a tabela com os resultados detalhados
  } else if (type_response == 1) {
    # Retornar verificação se algum grupo falha no teste de normalidade
    return(verificacao)
  }
}

df = df_ficticio(3*5000)
group_normality_test(df, 'idade', 'group1')
group_normality_test(df, 'idade', 'group1', 1)
```



```{r}
library(coin)

teste_num_cat = function(df, col_num, col_cat){

  qtd_levels = length(levels(as.factor(df[[col_cat]])))
  tam_grupos = table(df[[col_cat]])
  
  # Verifica se algum grupo tem tamanho menor que 30
  usa_permutacao = any(tam_grupos < 30)
  
  if (qtd_levels <= 2) {
    # A lógica existente para 2 categorias permanece a mesma
    if (group_normality_test(df, col_num, col_cat, 1)){
      formula = formula(paste0(col_num, '~', col_cat))
      
      # Teste de homogeneidade para 2 grupos
      teste_homogeneidade = bartlett.test(formula, df)
      
      if (teste_homogeneidade$p.value > 0.05){
        if (usa_permutacao) {
          # Aplica teste de permutação de Fisher-Pitman se algum grupo tiver n < 30
          teste_usado = "Student's T-test (Fisher-Pitman)"
          pvalor = coin::independence_test(df[[col_num]] ~ df[[col_cat]])$p.value
        } else {
          # Teste t de Student padrão
          teste_usado = "Student's T-test"
          pvalor = t.test(df[[col_num]] ~ df[[col_cat]], var.equal = TRUE)$p.value
        }
      } else {
        if (usa_permutacao) {
          # Aplica teste de permutação ajustado para variância desigual
          teste_usado = "Welch's T-test (Fisher-Pitman)"
          pvalor = coin::oneway_test(df[[col_num]] ~ df[[col_cat]]) %>% coin::pvalue()
        } else {
          # Teste t de Welch padrão
          teste_usado = "Welch's t-test"
          pvalor = t.test(df[[col_num]] ~ df[[col_cat]], var.equal = FALSE)$p.value
        }
      }
    } else {
      if (usa_permutacao) {
        # Aplica teste de permutação equivalente a Wilcoxon
        teste_usado = "Wilcoxon test with permutation (Fisher-Pitman)"
        pvalor = coin::wilcox_test(df[[col_num]] ~ df[[col_cat]]) %>% coin::pvalue()
      } else {
        # Teste de Mann-Whitney (Wilcoxon para 2 amostras)
        teste_usado = "Mann-Whitney"
        pvalor = wilcox.test(df[[col_num]] ~ df[[col_cat]])$p.value
      }
    }
  } else {
    # Quando houver mais de 2 categorias
    formula = formula(paste0(col_num, '~', col_cat))
    
    if (group_normality_test(df, col_num, col_cat, 1)){
      # Verificando homogeneidade para mais de 2 grupos
      teste_homogeneidade = bartlett.test(formula, df)
      
      if (teste_homogeneidade$p.value > 0.05){
        if (usa_permutacao) {
          # Aplica teste de permutação ANOVA
          teste_usado = "One-way ANOVA (Fisher-Pitman)"
          pvalor = coin::independence_test(df[[col_num]] ~ df[[col_cat]]) %>% coin::pvalue()
        } else {
          # ANOVA padrão
          pvalor = summary(aov(df[[col_num]] ~ df[[col_cat]]))[[1]][["Pr(>F)"]][1]
          teste_usado = "One-way ANOVA"
        }
      } else {
        if (usa_permutacao) {
          # Aplica Welch ANOVA ajustado para permutação
          teste_usado = "Welch's ANOVA (Fisher-Pitman)"
          pvalor = coin::oneway_test(df[[col_num]] ~ df[[col_cat]]) %>% coin::pvalue()
        } else {
          # Welch ANOVA padrão
          pvalor = oneway.test(df[[col_num]] ~ df[[col_cat]], var.equal = FALSE)$p.value
          teste_usado = "Welch's ANOVA"
        }
      }
    } else {
      if (usa_permutacao) {
        # Aplica teste de Kruskal-Wallis com permutação
        teste_usado = "Kruskal-Wallis (Fisher-Pitman)"
        pvalor = coin::independence_test(df[[col_num]] ~ df[[col_cat]]) %>% coin::pvalue()
      } else {
        # Kruskal-Wallis padrão
        pvalor = kruskal.test(df[[col_num]] ~ df[[col_cat]])$p.value
        teste_usado = "Kruskal-Wallis"
      }
    }
  }
  
  list(p.value = pvalor, 
       test = teste_usado)
}



n = 100
cat3 = c(rep("A", n), rep("B", n), rep('C', 50))
filtro_A = cat3 == "A"
filtro_B = cat3 == "B"
filtro_C = cat3 == "C"
df = data.frame(cat3 = cat3)
df$cat3 = as.factor(df$cat3)

df$numerica = NA
df$numerica[filtro_A] = rnorm(n, mean = 10, sd = 20)
df$numerica[filtro_B] = rnorm(n, mean = 30, sd = 40)

df$numerica[filtro_C] = rnorm(29, mean = 30, sd = 40); teste_num_cat(df, 'numerica', 'cat3')
df$numerica[filtro_C] = rpois(29, 40); teste_num_cat(df, 'numerica', 'cat3')
df$numerica[filtro_C] = runif(29); teste_num_cat(df, 'numerica', 'cat3')

########################################
df$numerica[filtro_C] = rnorm(35, mean = 30, sd = 40); teste_num_cat(df, 'numerica', 'cat3')
df$numerica[filtro_C] = rpois(35, 40); teste_num_cat(df, 'numerica', 'cat3')
df$numerica[filtro_C] = runif(35); teste_num_cat(df, 'numerica', 'cat3')

df$numerica[filtro_A] = rnorm(n, mean = 10, sd = 40)
df$numerica[filtro_C] = rnorm(35, mean = 30, sd = 40); teste_num_cat(df, 'numerica', 'cat3')
```



```{r}
library(dplyr)
library(broom)

# Função para criar uma matriz adaptativa de correlações e testes
adaptive_matrix <- function(df) {
  n <- ncol(df)
  result <- matrix(NA, n, n)  # Inicializa a matriz com NA
  colnames(result) <- rownames(result) <- colnames(df)
  
  for (i in 1:n) {
    for (j in 1:n) {
      result[i, j] <- tryCatch({
        if (i == j) {
          "1"  # Correlation with itself
        } else if ( is.numeric(df[[i]]) && is.numeric(df[[j]]) ){
          #cor.test(df[[i]], df[[j]], use = "complete.obs") %>% tidy() %>% .$p.value %>% pval_string()
          cor.hip(df[[i]], df[[j]])$p.value %>% pval_string()
        } else if ( ( is.factor(df[[i]]) | is.character(df[[i]])) && is.numeric(df[[j]]) ){
          teste_num_cat(df, names(df[j]), names(df[i]) )$p.value %>% pval_string()
        } else if ( is.numeric(df[[i]]) && ( is.factor(df[[j]]) | is.character(df[[j]])) ){
          teste_num_cat(df, names(df[i]), names(df[j]) )$p.value %>% pval_string()
        } else if ( is.factor(df[[i]]) && is.factor(df[[j]]) ){
          chisq.test(table(df[[i]], df[[j]]), correct = F) %>% tidy() %>% .$p.value %>% pval_string()
        } else {
          NA  # Para casos inesperados
        }
      }, error = function(e) {
        NA  # Retorna NA em caso de erro
      })
    }
  }
  
  return(result)
}

# Aplicando a função ao seu data frame
result_matrix <- adaptive_matrix(dff) %>% as.data.frame()
print(result_matrix)

```






```{r}
# Definindo as variáveis
x <- dff$idade
y <- dff$peso

# Calculando a correlação observada
cor_obs <- cor(x, y, use = "complete.obs")

# Definindo os valores de correlação nula (-0.5 e 0.5)
rho_null_lower <- -0.5
rho_null_upper <- 0.5

# Transformação de Fisher
z_obs <- atanh(cor_obs)
z_null_lower <- atanh(rho_null_lower)
z_null_upper <- atanh(rho_null_upper)

# Calculando o valor de t para os dois limites
n <- sum(complete.cases(x, y))  # Número de observações válidas
t_value_lower <- (z_obs - z_null_lower) / sqrt(1 / (n - 3))
t_value_upper <- (z_obs - z_null_upper) / sqrt(1 / (n - 3))

# Calculando os p-values para ambas as hipóteses alternativas
p_value_lower <- pt(t_value_lower, df = n - 1, lower.tail = TRUE)
p_value_upper <- pt(t_value_upper, df = n - 1, lower.tail = FALSE)

# Combinação dos p-values para o teste bicaudal
p_value_combined <- 2 * min(p_value_lower, p_value_upper)

# Resultado
list(
  cor = cor_obs,
  t_value_lower = t_value_lower,
  t_value_upper = t_value_upper,
  p_value_lower = p_value_lower,
  p_value_upper = p_value_upper,
  p_value_combined = p_value_combined,
  alternative_hypothesis = "correlation < -0.5 or > 0.5"
)

```


```{r}
```


```{r}
```


```{r}
```


```{r}
```

